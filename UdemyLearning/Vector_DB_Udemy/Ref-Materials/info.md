# ğŸš€ Vector Databases for AI â€“ Learning Journey

Just wrapped up the **[Vector Databases for AI](https://www.udemy.com/course/vector-databases-ai/?couponCode=MT300725A)** course on Udemy! ğŸ“  
ğŸ“„ *Certificate Attached*

---

## ğŸ§  What I Learned

I've been diving deep into how LLM-based apps actually "remember" and "retrieve" information â€” and this course gave me a clear, hands-on understanding of vector databases and how they power features like **semantic search** and **Retrieval-Augmented Generation (RAG)**.

### ğŸ§© Core Concepts
- A **user query** is transformed into a **vector (embedding)** using models like `Sentence-BERT`, capturing its **semantic meaning**.
- These vectors are then **stored** in a **vector database** such as:
  - `Chroma`
  - `Pinecone`
  - `Weaviate`
- On receiving a new query:
  - It's converted to a vector.
  - The system searches for **similar vectors** in the database.
  - It returns **contextually relevant** results â€” even if the query doesn't match the exact wording.

---

## ğŸ“š Additional Resources That Helped

| Resource                                                                                                                                    | Description                                                  |
| ------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------ |
| [ğŸ§© Illustrated Transformer â€“ by Jay Alammar](http://jalammar.github.io/illustrated-transformer/)                                           | A visual introduction to the Transformer architecture        |
| [ğŸ”— SBERT â€“ Semantic Search Examples](https://www.sbert.net/examples/applications/semantic-search/README.html)                              | Practical examples of semantic search using SBERT            |
| [ğŸ” Semantic Textual Similarity â€“ SBERT Docs](https://www.sbert.net/docs/pretrained_models.html#semantic-textual-similarity)                | Details on how SBERT computes similarity between sentences   |
| [ğŸ¤– Sentence Transformers â€“ Hugging Face Space](https://huggingface.co/spaces/sentence-transformers/embeddings-semantic-search)                        | An interactive playground for sentence embeddings            |
| [ğŸ’¡ Mindful CTO's Intro to Vector DBs](https://mindfulcto.com/supercharge-your-openai-embeddings-workflow-with-chroma-db-a-comprehensive-tutorial-4b7fa7503ceb)                                               | A concise overview of how vector databases work              |
| [ğŸ§  Understanding Vector Databases â€“ Mindful CTO Primer](https://mindfulcto.com/understanding-vector-databases-a-brief-primer-b18a1468ac0f) | Another solid primer diving deeper into vector DB principles |


## ğŸ¯ What's Next

Now feeling confident to:
- Experiment with **LangChain**
- Try out various **embedding models**
- Build smarter, more memory-efficient **AI workflows**

---

## ğŸ§  Keywords

`#AI` `#LLMs` `#VectorDatabase` `#SemanticSearch` `#Embeddings`  
`#LangChain` `#SBERT` `#Chroma` `#Pinecone` `#Weaviate` `#Python` `#Udemy` `#LearningJourney`

---

Thanks for reading! Feel free to reach out if you're exploring this space too! ğŸš€
